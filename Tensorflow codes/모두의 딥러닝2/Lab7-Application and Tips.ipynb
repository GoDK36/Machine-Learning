{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow==2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (2.3.0)\nRequirement already satisfied: absl-py>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.9.0)\nRequirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.3.0)\nRequirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.18.5)\nRequirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.12.1)\nRequirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.15.0)\nRequirement already satisfied: gast==0.3.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.3.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (3.1.0)\nRequirement already satisfied: wheel>=0.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.34.2)\nRequirement already satisfied: google-pasta>=0.1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.2.0)\nRequirement already satisfied: scipy==1.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.4.1)\nRequirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (3.12.3)\nRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.1.2)\nRequirement already satisfied: astunparse==1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.6.3)\nRequirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.3.0)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.10.0)\nRequirement already satisfied: grpcio>=1.8.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.26.0)\nRequirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (49.2.0.post20200714)\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.24.0)\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.6.0)\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.16.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.17.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\nRequirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'GceClusterResolver' from 'tensorflow.python.distribute.cluster_resolver.gce_cluster_resolver' (C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\gce_cluster_resolver.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c181874f8e27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"nt\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster_resolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cluster_resolver\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleClusterResolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnionClusterResolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgce_cluster_resolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGceClusterResolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkubernetes_cluster_resolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKubernetesClusterResolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslurm_cluster_resolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSlurmClusterResolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GceClusterResolver' from 'tensorflow.python.distribute.cluster_resolver.gce_cluster_resolver' (C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\gce_cluster_resolver.py)"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(hypothesis, labels)\n",
    "    return tape.gradient(loss_value, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expotential_decay(epoch):\n",
    "    starter_rate = 0.01\n",
    "    k = 0.96\n",
    "    exp_rate = starter_rate * exp(-k*t)\n",
    "    return exp_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization = (data - np.mean(data)) / np.sqrt(np.sum((data - np.mean(data))^2) / np.count(data))\n",
    "\n",
    "# Normalization = (data - np.min(data, 0)) / (np.max(data, 0) - np.min(data, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 3)\n",
    "# pca.fit(X)\n",
    "# X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2_loss = tf.nn.l2_loss(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "              [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "              [819.929993, 824.400021, 1438100, 818.97998, 824.159973],\n",
    "              [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "              [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "              [819, 823, 1198100, 816, 820.450012],\n",
    "              [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_train = xy[:, 0:-1]\n",
    "y_train = xy[:, [-1]]\n",
    "\n",
    "def normalization(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "xy = normalization(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'random_normal'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dba79f13cdff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'random_normal'"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), dtype=tf.float32)\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32)\n",
    "\n",
    "def linearReg_fn(features):\n",
    "    hypothesis = tf.matmul(features, W) + b\n",
    "\n",
    "    return hypothesis\n",
    "\n",
    "def l2_loss(loss, beta = 0.01):\n",
    "    W_reg = tf.nn.l2_loss(W)\n",
    "    loss = tf.reduce_mean(loss + W_reg * beta)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_fn(hypothesis, labels, flag=False):\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - labels))\n",
    "    if(flag):\n",
    "        cost = l2_loss(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'exponential_decay'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-55b56ecb0180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexponential_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstarter_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstaircase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'exponential_decay'"
     ]
    }
   ],
   "source": [
    "is_decay = True\n",
    "starter_learning_rate = 0.1\n",
    "\n",
    "if (is_decay):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 50, 0.96, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "else:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=starter_learning_rate)\n",
    "\n",
    "def grad(features, labels, l2_flag):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(linearReg_fn(features), labels, l2_flag)\n",
    "    \n",
    "    return tape.gradient(loss_value, [W, b]), loss_value\n",
    "\n",
    "for step in range(101):\n",
    "    for features, labels in tf.contrib.enable_eager_execution.Iterator(dataset):\n",
    "        features = tf.cast(labels, tf.float32)\n",
    "        grads, loss_value = grad(linearReg_fn(features), features, labels, False)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]), global_step=global_step)\n",
    "        if step % 10 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}, Learning Rate: {:.8f}\".format(step, loss_value, optimizer._learning_rate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (train_images, test_labels) = fasion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='ada,',\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda7ccc1197ea424c04aa8e970980241a68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
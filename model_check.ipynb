{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda7ccc1197ea424c04aa8e970980241a68",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##편향되지 않는 모델 성능 측정하기\n",
    "##머신 러닝 알고리즘에서 일반적으로 발생하는 문제 분석하기\n",
    "##머신 러닝 모델 세부 튜닝하기\n",
    "##여러 가지 성능 지표를 사용하여 모델의 예측 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####파이프라인을 사용한 워크 플로####\n",
    "##여러개의 변환 단계를 포함한 모델을 학습하고 새로운 데이터에 대한 예측 생성 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>",
      "text/plain": "         0  1      2      3       4       5        6        7       8   \\\n0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n\n        9   ...     22     23      24      25      26      27      28      29  \\\n0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n\n       30       31  \n0  0.4601  0.11890  \n1  0.2750  0.08902  \n2  0.3613  0.08758  \n3  0.6638  0.17300  \n4  0.2364  0.07678  \n\n[5 rows x 32 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##훈련 세트와 테스트 세트로 분할하기\n",
    "\n",
    "#유방암 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'E:\\Programming\\python\\ML\\data\\wdbc.data', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['B', 'M'], dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#30개의 특성을 넘파이 배열 X에 할당. LabelEncoder 객체를 사용하여 원본 문자열에서 정수로 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0], dtype=int64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#악성(Benign)은 클래스 1로 표현, 양성(Malignant)는 클래스 0으로 표현된다\n",
    "le.transform(['M','B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련세트 80%, 테스트 세트 20%로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "테스트 정확도: 0.956\n"
    }
   ],
   "source": [
    "##PCA를 통해 30차원의 데이터를 2차원으로 낮추기\n",
    "#StandardScaler, PCA, LogisticRegression을 하나의 파이프라인으로 연결\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        LogisticRegression(solver='liblinear', random_state=1))\n",
    "pipe_lr.fit(X_train, y_train) #pipline에 묶여있는 모든 변환기의 fit과 transform 메서드를 차례로 거쳐 추정기 객체에 도달한다.\n",
    "y_pred = pipe_lr.predict(X_test) #predict 메서드는 마지막 추정기 객체가 변환된 데이터의 예측을 반환한다.\n",
    "print('테스트 정확도: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##사이킷런 변환기 중 fit/transform 메서드를 지원하는 객체에 한에서 make_pipline 함수를 이용해 연결 가능하다.\n",
    "#위의 pipline 예시를 분석해보면 우선적으로 StandardScaler의 fit과 transform 메서드를 거쳐 변환된 데이터를 PCA 객체로 전달되 저차원으로 변환한 후 LogisticRegression 모델이 변환된 데이터로 학습한다. 중간단계의 개수 제한은 없지만 중요한 점은 마지막 단계는 항상 추정기가 되어야한다는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####홀드아웃 교차 검증####\n",
    "#1. 초기 데이터셋을 별도의 훈련세트(모델 훈련용)와 테스트 세트(일반화 성능 추정용)로 나눈다\n",
    "##모델선택(예측 성능을 높이기 위해 하이퍼파라미터를 튜닝하고 비교하는 과정 중 최적의 파라미터를 선택한는 것)에서 테스트 세트를 계속 사용하면 과대 적합이 된다.\n",
    "#2. 홀드 아웃에선 훈련세트를 다시 훈련세트(여러가지 모델 훈련), 검증 세트(최적의 파라미터가 나올때까지 반복적으로 모델 성능 평가), 그 후 기존에 사용하지 않은(모델 입장에선 처음 마주한) 테스트 세트를 통해 성능평가 실시\n",
    "#단점: 훈련 데이터를 어떤 방법으로 검증과 훈련 데이터 세트로 나누느냐에 따라 성능 추정이 민감할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####k-겹 교차 검증####\n",
    "#중복을 허락하지 X => 검증에 한 번만 사용되는 장점\n",
    "#1. 훈련 데이터셋을 k개의 폴드로 랜덤하게 나눔\n",
    "#2. k-1개의 폴드로 모델을 훈련하고 남은 한 개로 모델을 평가\n",
    "#3. 이 과정을 k번 반복하여 k개의 모델과 성능 추정을 얻는다\n",
    "#4. 독립적인 모델들의 평균 성능을 계산\n",
    "##주로 최적의 파라미터를 찾기 위해 사용\n",
    "#5. 최적의 파라미터를 찾은 후엔 전체 훈련 세트를 사용하여 모델을 다시 훈련한다(전체 훈련 세트를 사용하는 이유는 훈련 세트가 클수록 알고리즘이 더 정확하고 안정적이기 때문)\n",
    "#6. 독립적인 테스트 세트를 사용해서 최종 성능을 추정한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####계층적 k-겹 교차 검증####\n",
    "##클래스 비율이 동등하지 않을때 좀 더 나은 편향과 분산 추정을 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "폴드:  1, 클래스 분포: [256 153], 정확도: 0.935\n폴드:  2, 클래스 분포: [256 153], 정확도: 0.935\n폴드:  3, 클래스 분포: [256 153], 정확도: 0.957\n폴드:  4, 클래스 분포: [256 153], 정확도: 0.957\n폴드:  5, 클래스 분포: [256 153], 정확도: 0.935\n폴드:  6, 클래스 분포: [257 153], 정확도: 0.956\n폴드:  7, 클래스 분포: [257 153], 정확도: 0.978\n폴드:  8, 클래스 분포: [257 153], 정확도: 0.933\n폴드:  9, 클래스 분포: [257 153], 정확도: 0.956\n폴드: 10, 클래스 분포: [257 153], 정확도: 0.956\n\nCV 정확도: 0.950 +/- 0.014\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, #훈련세트의 y_train 클래스 레이블을 전달해서 초기화 / n_splits로 폴드 개수 지정\n",
    "                        random_state=1).split(X_train, y_train) \n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('폴드: %2d, 클래스 분포: %s, 정확도: %.3f' % (k+1, np.bincount(y_train[train]), score))\n",
    "print('\\nCV 정확도: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "CV 정확도 점수: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n 0.97777778 0.93333333 0.95555556 0.95555556]\nCV 정확도: 0.950 +/- 0.014\n"
    }
   ],
   "source": [
    "#계층별 k-겹 교차 검증 사용\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1) #하나의 cpu코어만 성능평가에 참여 (2로 설정하면 두개의 코어에 교차검증을 10회씩 분산/-1은 설치된 모든 코어에 병렬처리)\n",
    "print('CV 정확도 점수: %s' % scores)\n",
    "print('CV 정확도: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
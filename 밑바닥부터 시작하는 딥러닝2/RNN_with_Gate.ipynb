{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 폭발 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1. 1. 1.]\n [1. 1. 1.]]\n[[ 1.78862847  0.43650985  0.09649747]\n [-1.8634927  -0.2773882  -0.35475898]\n [-0.08274148 -0.62700068 -0.04381817]]\n2.4684068094579303\n3.335704974161037\n4.783279375373183\n6.2795873320876145\n8.080776465019055\n10.25116303229294\n12.9360635066099\n16.276861327786712\n20.454829618345983\n25.688972842084684\n32.25315718048336\n40.48895641683869\n50.824407307019094\n63.79612654485427\n80.07737014308985\n100.51298922051251\n126.16331847536827\n158.3592064825883\n198.77107967611957\n249.495615421267\n"
    }
   ],
   "source": [
    "# RNN Matmul 노드의 역전파\n",
    "\n",
    "N = 2   # 미니배치 크기\n",
    "H = 3   # 은닉 상태 벡터의 차원 수\n",
    "T = 20  # 시계열 데이터의 길이\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)       # 재현할 수 있는 난수의 시드 고정\n",
    "Wh = np.random.randn(H, H)\n",
    "print(dh)\n",
    "print(Wh)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "    print(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 소실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1. 1. 1.]\n [1. 1. 1.]]\n[[ 0.89431424  0.21825493  0.04824873]\n [-0.93174635 -0.1386941  -0.17737949]\n [-0.04137074 -0.31350034 -0.02190908]]\n1.2342034047289652\n0.8339262435402592\n0.5979099219216478\n0.3924742082554759\n0.25252426453184545\n0.16017442237957719\n0.10106299614538984\n0.06358148956166684\n0.039950839098332\n0.025086887541098325\n0.015748611904532892\n0.009884999125204758\n0.006204151282595104\n0.003893806551809953\n0.002443767399386287\n0.0015337065005571367\n0.0009625497320203268\n0.0006040924319556743\n0.00037912574706291117\n0.00023793756048323344\n"
    }
   ],
   "source": [
    "N = 2   # 미니배치 크기\n",
    "H = 3   # 은닉 상태 벡터의 차원 수\n",
    "T = 20  # 시계열 데이터의 길이\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)       # 재현할 수 있는 난수의 시드 고정\n",
    "Wh = np.random.randn(H, H) * 0.5    # 초기값 변경\n",
    "print(dh)\n",
    "print(Wh)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "    print(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 클리핑\n",
    "### 기울기 폭발을 막는 전통적인 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
    "\n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time LSTM 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        \n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "        \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "import pickle\n",
    "\n",
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모으기\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "\n",
    "    def save_params(self, file_name=\"Rnnlm.pkl\"):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "    \n",
    "    def load_params(self, file_name=\"Rnnlm.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB 데이터셋 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 9999.69\n| 에폭 1 |  반복 21 / 1327 | 시간 15[s] | 퍼플렉서티 2965.95\n| 에폭 1 |  반복 41 / 1327 | 시간 29[s] | 퍼플렉서티 1249.66\n| 에폭 1 |  반복 61 / 1327 | 시간 43[s] | 퍼플렉서티 962.55\n| 에폭 1 |  반복 81 / 1327 | 시간 57[s] | 퍼플렉서티 796.55\n| 에폭 1 |  반복 101 / 1327 | 시간 71[s] | 퍼플렉서티 661.68\n| 에폭 1 |  반복 121 / 1327 | 시간 85[s] | 퍼플렉서티 651.81\n| 에폭 1 |  반복 141 / 1327 | 시간 99[s] | 퍼플렉서티 589.56\n| 에폭 1 |  반복 161 / 1327 | 시간 113[s] | 퍼플렉서티 585.20\n| 에폭 1 |  반복 181 / 1327 | 시간 127[s] | 퍼플렉서티 579.40\n| 에폭 1 |  반복 201 / 1327 | 시간 141[s] | 퍼플렉서티 508.90\n| 에폭 1 |  반복 221 / 1327 | 시간 155[s] | 퍼플렉서티 498.41\n| 에폭 1 |  반복 241 / 1327 | 시간 169[s] | 퍼플렉서티 444.40\n| 에폭 1 |  반복 261 / 1327 | 시간 183[s] | 퍼플렉서티 482.82\n| 에폭 1 |  반복 281 / 1327 | 시간 197[s] | 퍼플렉서티 450.57\n| 에폭 1 |  반복 301 / 1327 | 시간 211[s] | 퍼플렉서티 396.99\n| 에폭 1 |  반복 321 / 1327 | 시간 225[s] | 퍼플렉서티 344.93\n| 에폭 1 |  반복 341 / 1327 | 시간 239[s] | 퍼플렉서티 412.85\n| 에폭 1 |  반복 361 / 1327 | 시간 253[s] | 퍼플렉서티 409.24\n| 에폭 1 |  반복 381 / 1327 | 시간 267[s] | 퍼플렉서티 340.70\n| 에폭 1 |  반복 401 / 1327 | 시간 282[s] | 퍼플렉서티 353.53\n| 에폭 1 |  반복 421 / 1327 | 시간 296[s] | 퍼플렉서티 349.79\n| 에폭 1 |  반복 441 / 1327 | 시간 310[s] | 퍼플렉서티 337.98\n| 에폭 1 |  반복 461 / 1327 | 시간 324[s] | 퍼플렉서티 330.71\n| 에폭 1 |  반복 481 / 1327 | 시간 338[s] | 퍼플렉서티 307.68\n| 에폭 1 |  반복 501 / 1327 | 시간 352[s] | 퍼플렉서티 315.44\n| 에폭 1 |  반복 521 / 1327 | 시간 366[s] | 퍼플렉서티 308.19\n| 에폭 1 |  반복 541 / 1327 | 시간 380[s] | 퍼플렉서티 314.92\n| 에폭 1 |  반복 561 / 1327 | 시간 394[s] | 퍼플렉서티 286.68\n| 에폭 1 |  반복 581 / 1327 | 시간 408[s] | 퍼플렉서티 261.24\n| 에폭 1 |  반복 601 / 1327 | 시간 422[s] | 퍼플렉서티 336.84\n| 에폭 1 |  반복 621 / 1327 | 시간 436[s] | 퍼플렉서티 316.35\n| 에폭 1 |  반복 641 / 1327 | 시간 450[s] | 퍼플렉서티 285.76\n| 에폭 1 |  반복 661 / 1327 | 시간 464[s] | 퍼플렉서티 269.18\n| 에폭 1 |  반복 681 / 1327 | 시간 478[s] | 퍼플렉서티 232.13\n| 에폭 1 |  반복 701 / 1327 | 시간 492[s] | 퍼플렉서티 252.00\n| 에폭 1 |  반복 721 / 1327 | 시간 506[s] | 퍼플렉서티 261.65\n| 에폭 1 |  반복 741 / 1327 | 시간 520[s] | 퍼플렉서티 221.92\n| 에폭 1 |  반복 761 / 1327 | 시간 534[s] | 퍼플렉서티 235.49\n| 에폭 1 |  반복 781 / 1327 | 시간 548[s] | 퍼플렉서티 220.67\n| 에폭 1 |  반복 801 / 1327 | 시간 562[s] | 퍼플렉서티 243.88\n| 에폭 1 |  반복 821 / 1327 | 시간 576[s] | 퍼플렉서티 226.08\n| 에폭 1 |  반복 841 / 1327 | 시간 590[s] | 퍼플렉서티 231.98\n| 에폭 1 |  반복 861 / 1327 | 시간 604[s] | 퍼플렉서티 221.99\n| 에폭 1 |  반복 881 / 1327 | 시간 618[s] | 퍼플렉서티 207.42\n| 에폭 1 |  반복 901 / 1327 | 시간 632[s] | 퍼플렉서티 253.91\n| 에폭 1 |  반복 921 / 1327 | 시간 646[s] | 퍼플렉서티 227.29\n| 에폭 1 |  반복 941 / 1327 | 시간 660[s] | 퍼플렉서티 232.56\n| 에폭 1 |  반복 961 / 1327 | 시간 674[s] | 퍼플렉서티 245.44\n| 에폭 1 |  반복 981 / 1327 | 시간 688[s] | 퍼플렉서티 229.48\n| 에폭 1 |  반복 1001 / 1327 | 시간 702[s] | 퍼플렉서티 193.48\n| 에폭 1 |  반복 1021 / 1327 | 시간 716[s] | 퍼플렉서티 226.69\n| 에폭 1 |  반복 1041 / 1327 | 시간 730[s] | 퍼플렉서티 207.96\n| 에폭 1 |  반복 1061 / 1327 | 시간 744[s] | 퍼플렉서티 195.89\n| 에폭 1 |  반복 1081 / 1327 | 시간 758[s] | 퍼플렉서티 168.57\n| 에폭 1 |  반복 1101 / 1327 | 시간 772[s] | 퍼플렉서티 190.77\n| 에폭 1 |  반복 1121 / 1327 | 시간 786[s] | 퍼플렉서티 230.01\n| 에폭 1 |  반복 1141 / 1327 | 시간 800[s] | 퍼플렉서티 206.57\n| 에폭 1 |  반복 1161 / 1327 | 시간 814[s] | 퍼플렉서티 198.49\n| 에폭 1 |  반복 1181 / 1327 | 시간 828[s] | 퍼플렉서티 190.68\n| 에폭 1 |  반복 1201 / 1327 | 시간 842[s] | 퍼플렉서티 162.43\n| 에폭 1 |  반복 1221 / 1327 | 시간 856[s] | 퍼플렉서티 160.27\n| 에폭 1 |  반복 1241 / 1327 | 시간 870[s] | 퍼플렉서티 187.59\n| 에폭 1 |  반복 1261 / 1327 | 시간 884[s] | 퍼플렉서티 172.85\n| 에폭 1 |  반복 1281 / 1327 | 시간 898[s] | 퍼플렉서티 179.19\n| 에폭 1 |  반복 1301 / 1327 | 시간 912[s] | 퍼플렉서티 222.76\n| 에폭 1 |  반복 1321 / 1327 | 시간 926[s] | 퍼플렉서티 212.30\n| 에폭 2 |  반복 1 / 1327 | 시간 931[s] | 퍼플렉서티 224.20\n| 에폭 2 |  반복 21 / 1327 | 시간 945[s] | 퍼플렉서티 203.80\n| 에폭 2 |  반복 41 / 1327 | 시간 959[s] | 퍼플렉서티 189.81\n| 에폭 2 |  반복 61 / 1327 | 시간 973[s] | 퍼플렉서티 176.08\n| 에폭 2 |  반복 81 / 1327 | 시간 987[s] | 퍼플렉서티 158.39\n| 에폭 2 |  반복 101 / 1327 | 시간 1001[s] | 퍼플렉서티 153.07\n| 에폭 2 |  반복 121 / 1327 | 시간 1015[s] | 퍼플렉서티 160.25\n| 에폭 2 |  반복 141 / 1327 | 시간 1029[s] | 퍼플렉서티 177.44\n| 에폭 2 |  반복 161 / 1327 | 시간 1044[s] | 퍼플렉서티 193.40\n| 에폭 2 |  반복 181 / 1327 | 시간 1058[s] | 퍼플렉서티 202.05\n| 에폭 2 |  반복 201 / 1327 | 시간 1072[s] | 퍼플렉서티 185.55\n| 에폭 2 |  반복 221 / 1327 | 시간 1086[s] | 퍼플렉서티 184.79\n| 에폭 2 |  반복 241 / 1327 | 시간 1100[s] | 퍼플렉서티 177.19\n| 에폭 2 |  반복 261 / 1327 | 시간 1114[s] | 퍼플렉서티 185.31\n| 에폭 2 |  반복 281 / 1327 | 시간 1128[s] | 퍼플렉서티 186.71\n| 에폭 2 |  반복 301 / 1327 | 시간 1142[s] | 퍼플렉서티 167.61\n| 에폭 2 |  반복 321 / 1327 | 시간 1156[s] | 퍼플렉서티 139.60\n| 에폭 2 |  반복 341 / 1327 | 시간 1170[s] | 퍼플렉서티 171.29\n| 에폭 2 |  반복 361 / 1327 | 시간 1184[s] | 퍼플렉서티 199.67\n| 에폭 2 |  반복 381 / 1327 | 시간 1198[s] | 퍼플렉서티 153.56\n| 에폭 2 |  반복 401 / 1327 | 시간 1213[s] | 퍼플렉서티 167.57\n| 에폭 2 |  반복 421 / 1327 | 시간 1227[s] | 퍼플렉서티 153.92\n| 에폭 2 |  반복 441 / 1327 | 시간 1241[s] | 퍼플렉서티 161.94\n| 에폭 2 |  반복 461 / 1327 | 시간 1255[s] | 퍼플렉서티 157.57\n| 에폭 2 |  반복 481 / 1327 | 시간 1269[s] | 퍼플렉서티 156.63\n| 에폭 2 |  반복 501 / 1327 | 시간 1283[s] | 퍼플렉서티 168.88\n| 에폭 2 |  반복 521 / 1327 | 시간 1297[s] | 퍼플렉서티 173.69\n| 에폭 2 |  반복 541 / 1327 | 시간 1311[s] | 퍼플렉서티 174.07\n| 에폭 2 |  반복 561 / 1327 | 시간 1325[s] | 퍼플렉서티 156.06\n| 에폭 2 |  반복 581 / 1327 | 시간 1339[s] | 퍼플렉서티 137.26\n| 에폭 2 |  반복 601 / 1327 | 시간 1353[s] | 퍼플렉서티 189.70\n| 에폭 2 |  반복 621 / 1327 | 시간 1367[s] | 퍼플렉서티 182.93\n| 에폭 2 |  반복 641 / 1327 | 시간 1381[s] | 퍼플렉서티 163.51\n| 에폭 2 |  반복 661 / 1327 | 시간 1395[s] | 퍼플렉서티 153.82\n| 에폭 2 |  반복 681 / 1327 | 시간 1409[s] | 퍼플렉서티 129.73\n| 에폭 2 |  반복 701 / 1327 | 시간 1423[s] | 퍼플렉서티 150.63\n| 에폭 2 |  반복 721 / 1327 | 시간 1437[s] | 퍼플렉서티 160.19\n| 에폭 2 |  반복 741 / 1327 | 시간 1452[s] | 퍼플렉서티 133.12\n| 에폭 2 |  반복 761 / 1327 | 시간 1466[s] | 퍼플렉서티 133.44\n| 에폭 2 |  반복 781 / 1327 | 시간 1480[s] | 퍼플렉서티 135.76\n| 에폭 2 |  반복 801 / 1327 | 시간 1494[s] | 퍼플렉서티 147.57\n| 에폭 2 |  반복 821 / 1327 | 시간 1508[s] | 퍼플렉서티 144.07\n| 에폭 2 |  반복 841 / 1327 | 시간 1522[s] | 퍼플렉서티 145.35\n| 에폭 2 |  반복 861 / 1327 | 시간 1536[s] | 퍼플렉서티 144.50\n| 에폭 2 |  반복 881 / 1327 | 시간 1550[s] | 퍼플렉서티 129.36\n| 에폭 2 |  반복 901 / 1327 | 시간 1564[s] | 퍼플렉서티 166.14\n| 에폭 2 |  반복 921 / 1327 | 시간 1578[s] | 퍼플렉서티 146.95\n| 에폭 2 |  반복 941 / 1327 | 시간 1592[s] | 퍼플렉서티 154.30\n| 에폭 2 |  반복 961 / 1327 | 시간 1606[s] | 퍼플렉서티 163.53\n| 에폭 2 |  반복 981 / 1327 | 시간 1620[s] | 퍼플렉서티 154.93\n| 에폭 2 |  반복 1001 / 1327 | 시간 1634[s] | 퍼플렉서티 131.28\n| 에폭 2 |  반복 1021 / 1327 | 시간 1648[s] | 퍼플렉서티 155.87\n| 에폭 2 |  반복 1041 / 1327 | 시간 1662[s] | 퍼플렉서티 143.34\n| 에폭 2 |  반복 1061 / 1327 | 시간 1677[s] | 퍼플렉서티 128.29\n| 에폭 2 |  반복 1081 / 1327 | 시간 1691[s] | 퍼플렉서티 110.96\n| 에폭 2 |  반복 1101 / 1327 | 시간 1705[s] | 퍼플렉서티 118.95\n| 에폭 2 |  반복 1121 / 1327 | 시간 1720[s] | 퍼플렉서티 154.29\n| 에폭 2 |  반복 1141 / 1327 | 시간 1734[s] | 퍼플렉서티 142.52\n| 에폭 2 |  반복 1161 / 1327 | 시간 1748[s] | 퍼플렉서티 132.11\n| 에폭 2 |  반복 1181 / 1327 | 시간 1762[s] | 퍼플렉서티 133.11\n| 에폭 2 |  반복 1201 / 1327 | 시간 1776[s] | 퍼플렉서티 111.86\n| 에폭 2 |  반복 1221 / 1327 | 시간 1790[s] | 퍼플렉서티 109.36\n| 에폭 2 |  반복 1241 / 1327 | 시간 1804[s] | 퍼플렉서티 130.06\n| 에폭 2 |  반복 1261 / 1327 | 시간 1818[s] | 퍼플렉서티 123.99\n| 에폭 2 |  반복 1281 / 1327 | 시간 1832[s] | 퍼플렉서티 122.93\n| 에폭 2 |  반복 1301 / 1327 | 시간 1846[s] | 퍼플렉서티 156.82\n| 에폭 2 |  반복 1321 / 1327 | 시간 1860[s] | 퍼플렉서티 152.37\n| 에폭 3 |  반복 1 / 1327 | 시간 1865[s] | 퍼플렉서티 161.91\n| 에폭 3 |  반복 21 / 1327 | 시간 1879[s] | 퍼플렉서티 143.47\n| 에폭 3 |  반복 41 / 1327 | 시간 1893[s] | 퍼플렉서티 136.05\n| 에폭 3 |  반복 61 / 1327 | 시간 1907[s] | 퍼플렉서티 126.99\n| 에폭 3 |  반복 81 / 1327 | 시간 1921[s] | 퍼플렉서티 117.24\n| 에폭 3 |  반복 101 / 1327 | 시간 1935[s] | 퍼플렉서티 105.80\n| 에폭 3 |  반복 121 / 1327 | 시간 1949[s] | 퍼플렉서티 117.07\n| 에폭 3 |  반복 141 / 1327 | 시간 1963[s] | 퍼플렉서티 125.84\n| 에폭 3 |  반복 161 / 1327 | 시간 1977[s] | 퍼플렉서티 142.87\n| 에폭 3 |  반복 181 / 1327 | 시간 1991[s] | 퍼플렉서티 151.25\n| 에폭 3 |  반복 201 / 1327 | 시간 2006[s] | 퍼플렉서티 140.80\n| 에폭 3 |  반복 221 / 1327 | 시간 2020[s] | 퍼플렉서티 141.04\n| 에폭 3 |  반복 241 / 1327 | 시간 2034[s] | 퍼플렉서티 134.81\n| 에폭 3 |  반복 261 / 1327 | 시간 2048[s] | 퍼플렉서티 139.71\n| 에폭 3 |  반복 281 / 1327 | 시간 2062[s] | 퍼플렉서티 141.81\n| 에폭 3 |  반복 301 / 1327 | 시간 2076[s] | 퍼플렉서티 124.94\n| 에폭 3 |  반복 321 / 1327 | 시간 2090[s] | 퍼플렉서티 103.57\n| 에폭 3 |  반복 341 / 1327 | 시간 2104[s] | 퍼플렉서티 123.30\n| 에폭 3 |  반복 361 / 1327 | 시간 2118[s] | 퍼플렉서티 151.76\n| 에폭 3 |  반복 381 / 1327 | 시간 2132[s] | 퍼플렉서티 114.47\n| 에폭 3 |  반복 401 / 1327 | 시간 2146[s] | 퍼플렉서티 129.04\n| 에폭 3 |  반복 421 / 1327 | 시간 2160[s] | 퍼플렉서티 112.52\n| 에폭 3 |  반복 441 / 1327 | 시간 2174[s] | 퍼플렉서티 123.43\n| 에폭 3 |  반복 461 / 1327 | 시간 2188[s] | 퍼플렉서티 119.14\n| 에폭 3 |  반복 481 / 1327 | 시간 2202[s] | 퍼플렉서티 119.84\n| 에폭 3 |  반복 501 / 1327 | 시간 2216[s] | 퍼플렉서티 127.98\n| 에폭 3 |  반복 521 / 1327 | 시간 2230[s] | 퍼플렉서티 137.84\n| 에폭 3 |  반복 541 / 1327 | 시간 2244[s] | 퍼플렉서티 135.94\n| 에폭 3 |  반복 561 / 1327 | 시간 2258[s] | 퍼플렉서티 118.87\n| 에폭 3 |  반복 581 / 1327 | 시간 2272[s] | 퍼플렉서티 104.46\n| 에폭 3 |  반복 601 / 1327 | 시간 2286[s] | 퍼플렉서티 147.07\n| 에폭 3 |  반복 621 / 1327 | 시간 2300[s] | 퍼플렉서티 142.52\n| 에폭 3 |  반복 641 / 1327 | 시간 2315[s] | 퍼플렉서티 129.56\n| 에폭 3 |  반복 661 / 1327 | 시간 2329[s] | 퍼플렉서티 120.33\n| 에폭 3 |  반복 681 / 1327 | 시간 2343[s] | 퍼플렉서티 100.43\n| 에폭 3 |  반복 701 / 1327 | 시간 2357[s] | 퍼플렉서티 118.24\n| 에폭 3 |  반복 721 / 1327 | 시간 2371[s] | 퍼플렉서티 126.13\n| 에폭 3 |  반복 741 / 1327 | 시간 2385[s] | 퍼플렉서티 107.06\n| 에폭 3 |  반복 761 / 1327 | 시간 2399[s] | 퍼플렉서티 103.88\n| 에폭 3 |  반복 781 / 1327 | 시간 2413[s] | 퍼플렉서티 104.45\n| 에폭 3 |  반복 801 / 1327 | 시간 2427[s] | 퍼플렉서티 115.37\n| 에폭 3 |  반복 821 / 1327 | 시간 2441[s] | 퍼플렉서티 116.07\n| 에폭 3 |  반복 841 / 1327 | 시간 2455[s] | 퍼플렉서티 115.04\n| 에폭 3 |  반복 861 / 1327 | 시간 2469[s] | 퍼플렉서티 117.49\n| 에폭 3 |  반복 881 / 1327 | 시간 2483[s] | 퍼플렉서티 105.27\n| 에폭 3 |  반복 901 / 1327 | 시간 2497[s] | 퍼플렉서티 130.80\n| 에폭 3 |  반복 921 / 1327 | 시간 2511[s] | 퍼플렉서티 118.14\n| 에폭 3 |  반복 941 / 1327 | 시간 2525[s] | 퍼플렉서티 127.29\n| 에폭 3 |  반복 961 / 1327 | 시간 2539[s] | 퍼플렉서티 131.85\n| 에폭 3 |  반복 981 / 1327 | 시간 2553[s] | 퍼플렉서티 124.93\n| 에폭 3 |  반복 1001 / 1327 | 시간 2567[s] | 퍼플렉서티 109.11\n| 에폭 3 |  반복 1021 / 1327 | 시간 2581[s] | 퍼플렉서티 128.18\n| 에폭 3 |  반복 1041 / 1327 | 시간 2595[s] | 퍼플렉서티 119.05\n| 에폭 3 |  반복 1061 / 1327 | 시간 2609[s] | 퍼플렉서티 103.14\n| 에폭 3 |  반복 1081 / 1327 | 시간 2623[s] | 퍼플렉서티 88.66\n| 에폭 3 |  반복 1101 / 1327 | 시간 2637[s] | 퍼플렉서티 94.39\n| 에폭 3 |  반복 1121 / 1327 | 시간 2651[s] | 퍼플렉서티 121.63\n| 에폭 3 |  반복 1141 / 1327 | 시간 2665[s] | 퍼플렉서티 115.66\n| 에폭 3 |  반복 1161 / 1327 | 시간 2679[s] | 퍼플렉서티 106.77\n| 에폭 3 |  반복 1181 / 1327 | 시간 2693[s] | 퍼플렉서티 110.15\n| 에폭 3 |  반복 1201 / 1327 | 시간 2707[s] | 퍼플렉서티 93.70\n| 에폭 3 |  반복 1221 / 1327 | 시간 2721[s] | 퍼플렉서티 89.56\n| 에폭 3 |  반복 1241 / 1327 | 시간 2735[s] | 퍼플렉서티 104.72\n| 에폭 3 |  반복 1261 / 1327 | 시간 2749[s] | 퍼플렉서티 104.52\n| 에폭 3 |  반복 1281 / 1327 | 시간 2763[s] | 퍼플렉서티 101.02\n| 에폭 3 |  반복 1301 / 1327 | 시간 2777[s] | 퍼플렉서티 129.29\n| 에폭 3 |  반복 1321 / 1327 | 시간 2791[s] | 퍼플렉서티 127.11\n| 에폭 4 |  반복 1 / 1327 | 시간 2796[s] | 퍼플렉서티 134.39\n| 에폭 4 |  반복 21 / 1327 | 시간 2810[s] | 퍼플렉서티 121.72\n| 에폭 4 |  반복 41 / 1327 | 시간 2824[s] | 퍼플렉서티 108.64\n| 에폭 4 |  반복 61 / 1327 | 시간 2838[s] | 퍼플렉서티 107.42\n| 에폭 4 |  반복 81 / 1327 | 시간 2852[s] | 퍼플렉서티 96.14\n| 에폭 4 |  반복 101 / 1327 | 시간 2866[s] | 퍼플렉서티 87.33\n| 에폭 4 |  반복 121 / 1327 | 시간 2880[s] | 퍼플렉서티 96.39\n| 에폭 4 |  반복 141 / 1327 | 시간 2894[s] | 퍼플렉서티 103.22\n| 에폭 4 |  반복 161 / 1327 | 시간 2908[s] | 퍼플렉서티 118.08\n| 에폭 4 |  반복 181 / 1327 | 시간 2922[s] | 퍼플렉서티 129.32\n| 에폭 4 |  반복 201 / 1327 | 시간 2936[s] | 퍼플렉서티 120.44\n| 에폭 4 |  반복 221 / 1327 | 시간 2950[s] | 퍼플렉서티 122.64\n| 에폭 4 |  반복 241 / 1327 | 시간 2964[s] | 퍼플렉서티 115.09\n| 에폭 4 |  반복 261 / 1327 | 시간 2978[s] | 퍼플렉서티 114.19\n| 에폭 4 |  반복 281 / 1327 | 시간 2992[s] | 퍼플렉서티 121.44\n| 에폭 4 |  반복 301 / 1327 | 시간 3006[s] | 퍼플렉서티 103.79\n| 에폭 4 |  반복 321 / 1327 | 시간 3020[s] | 퍼플렉서티 84.94\n| 에폭 4 |  반복 341 / 1327 | 시간 3034[s] | 퍼플렉서티 99.96\n| 에폭 4 |  반복 361 / 1327 | 시간 3048[s] | 퍼플렉서티 127.69\n| 에폭 4 |  반복 381 / 1327 | 시간 3062[s] | 퍼플렉서티 97.06\n| 에폭 4 |  반복 401 / 1327 | 시간 3076[s] | 퍼플렉서티 110.55\n| 에폭 4 |  반복 421 / 1327 | 시간 3090[s] | 퍼플렉서티 93.91\n| 에폭 4 |  반복 441 / 1327 | 시간 3104[s] | 퍼플렉서티 103.20\n| 에폭 4 |  반복 461 / 1327 | 시간 3118[s] | 퍼플렉서티 99.69\n| 에폭 4 |  반복 481 / 1327 | 시간 3132[s] | 퍼플렉서티 103.49\n| 에폭 4 |  반복 501 / 1327 | 시간 3146[s] | 퍼플렉서티 108.06\n| 에폭 4 |  반복 521 / 1327 | 시간 3160[s] | 퍼플렉서티 116.02\n| 에폭 4 |  반복 541 / 1327 | 시간 3174[s] | 퍼플렉서티 113.08\n| 에폭 4 |  반복 561 / 1327 | 시간 3188[s] | 퍼플렉서티 102.89\n| 에폭 4 |  반복 581 / 1327 | 시간 3202[s] | 퍼플렉서티 89.06\n| 에폭 4 |  반복 601 / 1327 | 시간 3216[s] | 퍼플렉서티 126.01\n| 에폭 4 |  반복 621 / 1327 | 시간 3231[s] | 퍼플렉서티 121.10\n| 에폭 4 |  반복 641 / 1327 | 시간 3245[s] | 퍼플렉서티 110.79\n| 에폭 4 |  반복 661 / 1327 | 시간 3259[s] | 퍼플렉서티 102.48\n| 에폭 4 |  반복 681 / 1327 | 시간 3273[s] | 퍼플렉서티 85.14\n| 에폭 4 |  반복 701 / 1327 | 시간 3287[s] | 퍼플렉서티 101.66\n| 에폭 4 |  반복 721 / 1327 | 시간 3301[s] | 퍼플렉서티 107.61\n| 에폭 4 |  반복 741 / 1327 | 시간 3315[s] | 퍼플렉서티 94.88\n| 에폭 4 |  반복 761 / 1327 | 시간 3329[s] | 퍼플렉서티 89.73\n| 에폭 4 |  반복 781 / 1327 | 시간 3343[s] | 퍼플렉서티 89.58\n| 에폭 4 |  반복 801 / 1327 | 시간 3357[s] | 퍼플렉서티 97.42\n| 에폭 4 |  반복 821 / 1327 | 시간 3371[s] | 퍼플렉서티 101.98\n| 에폭 4 |  반복 841 / 1327 | 시간 3385[s] | 퍼플렉서티 98.26\n| 에폭 4 |  반복 861 / 1327 | 시간 3399[s] | 퍼플렉서티 102.27\n| 에폭 4 |  반복 881 / 1327 | 시간 3413[s] | 퍼플렉서티 90.51\n| 에폭 4 |  반복 901 / 1327 | 시간 3427[s] | 퍼플렉서티 115.58\n| 에폭 4 |  반복 921 / 1327 | 시간 3441[s] | 퍼플렉서티 104.12\n| 에폭 4 |  반복 941 / 1327 | 시간 3455[s] | 퍼플렉서티 112.34\n| 에폭 4 |  반복 961 / 1327 | 시간 3469[s] | 퍼플렉서티 112.33\n| 에폭 4 |  반복 981 / 1327 | 시간 3483[s] | 퍼플렉서티 108.48\n| 에폭 4 |  반복 1001 / 1327 | 시간 3497[s] | 퍼플렉서티 97.69\n| 에폭 4 |  반복 1021 / 1327 | 시간 3511[s] | 퍼플렉서티 112.23\n| 에폭 4 |  반복 1041 / 1327 | 시간 3525[s] | 퍼플렉서티 104.11\n| 에폭 4 |  반복 1061 / 1327 | 시간 3539[s] | 퍼플렉서티 89.25\n| 에폭 4 |  반복 1081 / 1327 | 시간 3553[s] | 퍼플렉서티 79.13\n| 에폭 4 |  반복 1101 / 1327 | 시간 3567[s] | 퍼플렉서티 78.79\n| 에폭 4 |  반복 1121 / 1327 | 시간 3581[s] | 퍼플렉서티 103.06\n| 에폭 4 |  반복 1141 / 1327 | 시간 3595[s] | 퍼플렉서티 100.67\n| 에폭 4 |  반복 1161 / 1327 | 시간 3609[s] | 퍼플렉서티 91.36\n| 에폭 4 |  반복 1181 / 1327 | 시간 3623[s] | 퍼플렉서티 96.24\n| 에폭 4 |  반복 1201 / 1327 | 시간 3637[s] | 퍼플렉서티 83.41\n| 에폭 4 |  반복 1221 / 1327 | 시간 3651[s] | 퍼플렉서티 77.06\n| 에폭 4 |  반복 1241 / 1327 | 시간 3665[s] | 퍼플렉서티 90.82\n| 에폭 4 |  반복 1261 / 1327 | 시간 3679[s] | 퍼플렉서티 93.61\n| 에폭 4 |  반복 1281 / 1327 | 시간 3694[s] | 퍼플렉서티 89.75\n| 에폭 4 |  반복 1301 / 1327 | 시간 3708[s] | 퍼플렉서티 111.13\n| 에폭 4 |  반복 1321 / 1327 | 시간 3722[s] | 퍼플렉서티 111.80\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"265.995469pt\" version=\"1.1\" viewBox=\"0 0 388.965625 265.995469\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 265.995469 \r\nL 388.965625 265.995469 \r\nL 388.965625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.965625 228.439219 \r\nL 381.765625 228.439219 \r\nL 381.765625 10.999219 \r\nL 46.965625 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6b422cd387\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.183807\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(59.002557 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.180742\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(112.818242 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.177678\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(166.633928 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.174614\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(223.630864 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"290.171549\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 200 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(280.627799 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"347.168485\" xlink:href=\"#m6b422cd387\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 250 -->\r\n      <g transform=\"translate(337.624735 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- 반복 (x20) -->\r\n     <defs>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-48152\"/>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-48373\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 31 75.875 \r\nQ 24.46875 64.65625 21.28125 53.65625 \r\nQ 18.109375 42.671875 18.109375 31.390625 \r\nQ 18.109375 20.125 21.3125 9.0625 \r\nQ 24.515625 -2 31 -13.1875 \r\nL 23.1875 -13.1875 \r\nQ 15.875 -1.703125 12.234375 9.375 \r\nQ 8.59375 20.453125 8.59375 31.390625 \r\nQ 8.59375 42.28125 12.203125 53.3125 \r\nQ 15.828125 64.359375 23.1875 75.875 \r\nz\r\n\" id=\"DejaVuSans-40\"/>\r\n      <path d=\"M 54.890625 54.6875 \r\nL 35.109375 28.078125 \r\nL 55.90625 0 \r\nL 45.3125 0 \r\nL 29.390625 21.484375 \r\nL 13.484375 0 \r\nL 2.875 0 \r\nL 24.125 28.609375 \r\nL 4.6875 54.6875 \r\nL 15.28125 54.6875 \r\nL 29.78125 35.203125 \r\nL 44.28125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-120\"/>\r\n      <path d=\"M 8.015625 75.875 \r\nL 15.828125 75.875 \r\nQ 23.140625 64.359375 26.78125 53.3125 \r\nQ 30.421875 42.28125 30.421875 31.390625 \r\nQ 30.421875 20.453125 26.78125 9.375 \r\nQ 23.140625 -1.703125 15.828125 -13.1875 \r\nL 8.015625 -13.1875 \r\nQ 14.5 -2 17.703125 9.0625 \r\nQ 20.90625 20.125 20.90625 31.390625 \r\nQ 20.90625 42.671875 17.703125 53.65625 \r\nQ 14.5 64.65625 8.015625 75.875 \r\nz\r\n\" id=\"DejaVuSans-41\"/>\r\n     </defs>\r\n     <g transform=\"translate(193.551563 256.715781)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-48152\"/>\r\n      <use x=\"60.009766\" xlink:href=\"#DejaVuSans-48373\"/>\r\n      <use x=\"120.019531\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"151.806641\" xlink:href=\"#DejaVuSans-40\"/>\r\n      <use x=\"190.820312\" xlink:href=\"#DejaVuSans-120\"/>\r\n      <use x=\"250\" xlink:href=\"#DejaVuSans-50\"/>\r\n      <use x=\"313.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      <use x=\"377.246094\" xlink:href=\"#DejaVuSans-41\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mc6bb1b290b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(33.603125 232.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"184.951219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(20.878125 188.750437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"141.463219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(20.878125 145.262437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"97.975219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 300 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 101.774437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"54.487219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 400 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 58.286437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#mc6bb1b290b\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 500 -->\r\n      <g transform=\"translate(20.878125 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- 퍼플렉서티 -->\r\n     <defs>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-54140\"/>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-54540\"/>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-47113\"/>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-49436\"/>\r\n      <path d=\"M 4.984375 -17.671875 \r\nL 4.984375 70.515625 \r\nL 54.984375 70.515625 \r\nL 54.984375 -17.671875 \r\nz\r\nM 10.59375 -12.109375 \r\nL 49.421875 -12.109375 \r\nL 49.421875 64.890625 \r\nL 10.59375 64.890625 \r\nz\r\n\" id=\"DejaVuSans-54000\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 134.723125)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-54140\"/>\r\n      <use x=\"60.009766\" xlink:href=\"#DejaVuSans-54540\"/>\r\n      <use x=\"120.019531\" xlink:href=\"#DejaVuSans-47113\"/>\r\n      <use x=\"180.029297\" xlink:href=\"#DejaVuSans-49436\"/>\r\n      <use x=\"240.039062\" xlink:href=\"#DejaVuSans-54000\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#pc436fa5fe4)\" d=\"M 73.281014 -1 \r\nL 73.583194 7.127127 \r\nL 74.723133 11.690483 \r\nL 75.863071 35.180174 \r\nL 77.00301 18.468401 \r\nL 78.142949 32.497152 \r\nL 80.422826 78.436191 \r\nL 81.562765 48.899286 \r\nL 82.702704 50.468236 \r\nL 83.842642 80.275844 \r\nL 84.982581 74.694853 \r\nL 86.12252 76.321594 \r\nL 87.262459 81.460487 \r\nL 88.402397 84.620656 \r\nL 89.542336 94.63566 \r\nL 90.682275 91.259715 \r\nL 91.822213 94.413997 \r\nL 92.962152 91.486998 \r\nL 94.102091 103.766705 \r\nL 95.242029 114.831705 \r\nL 96.381968 81.953651 \r\nL 97.521907 90.863238 \r\nL 98.661846 104.16676 \r\nL 99.801784 111.380125 \r\nL 100.941723 127.490645 \r\nL 102.081662 118.850014 \r\nL 103.2216 114.653401 \r\nL 104.361539 131.929078 \r\nL 105.501478 126.030848 \r\nL 106.641417 132.473269 \r\nL 107.781355 122.381267 \r\nL 108.921294 130.123525 \r\nL 110.061233 127.556406 \r\nL 111.201171 131.902236 \r\nL 112.34111 138.237142 \r\nL 113.481049 118.020983 \r\nL 114.620988 129.59453 \r\nL 115.760926 127.303123 \r\nL 116.900865 121.703916 \r\nL 118.040804 128.64379 \r\nL 119.180742 144.300512 \r\nL 120.320681 129.856029 \r\nL 121.46062 138.003145 \r\nL 122.600559 143.250293 \r\nL 123.740497 155.129708 \r\nL 124.880436 145.479324 \r\nL 126.020375 128.414527 \r\nL 127.160313 138.605395 \r\nL 129.440191 145.516985 \r\nL 130.58013 157.800353 \r\nL 131.720068 158.739834 \r\nL 132.860007 146.859314 \r\nL 133.999946 153.26892 \r\nL 135.139884 150.511858 \r\nL 136.279823 131.567396 \r\nL 137.419762 136.112376 \r\nL 138.559701 130.938909 \r\nL 139.699639 139.812518 \r\nL 141.979517 151.867017 \r\nL 143.119455 159.557015 \r\nL 144.259394 161.871611 \r\nL 145.399333 158.747744 \r\nL 147.67921 144.334579 \r\nL 148.819149 140.571873 \r\nL 149.959088 147.745525 \r\nL 151.099026 148.077944 \r\nL 152.238965 151.381204 \r\nL 153.378904 147.851933 \r\nL 154.518843 147.241486 \r\nL 155.658781 155.550947 \r\nL 156.79872 167.731768 \r\nL 157.938659 153.947264 \r\nL 159.078597 141.608083 \r\nL 160.218536 161.657957 \r\nL 161.358475 155.568527 \r\nL 162.498414 161.502422 \r\nL 163.638352 158.014259 \r\nL 164.778291 159.913858 \r\nL 165.91823 160.324092 \r\nL 167.058168 154.997437 \r\nL 168.198107 152.903794 \r\nL 169.338046 152.741677 \r\nL 171.617923 168.746319 \r\nL 172.757862 145.941583 \r\nL 173.897801 148.88822 \r\nL 175.037739 157.331746 \r\nL 176.177678 161.545832 \r\nL 177.317617 172.022986 \r\nL 178.457556 162.93269 \r\nL 179.597494 158.777956 \r\nL 180.737433 170.549653 \r\nL 181.877372 170.410122 \r\nL 183.01731 169.399609 \r\nL 184.157249 164.262931 \r\nL 185.297188 165.78752 \r\nL 186.437127 165.229296 \r\nL 187.577065 165.600913 \r\nL 188.717004 172.184174 \r\nL 189.856943 156.188291 \r\nL 190.996881 164.534151 \r\nL 192.13682 161.337153 \r\nL 193.276759 157.323658 \r\nL 194.416698 161.063848 \r\nL 195.556636 171.347398 \r\nL 196.696575 160.654131 \r\nL 197.836514 166.102229 \r\nL 198.976452 172.648444 \r\nL 200.116391 180.183141 \r\nL 201.25633 176.709212 \r\nL 202.396269 161.339473 \r\nL 203.536207 166.46013 \r\nL 204.676146 170.987265 \r\nL 205.816085 170.554113 \r\nL 206.956023 179.79207 \r\nL 208.095962 180.879475 \r\nL 209.235901 171.878211 \r\nL 210.37584 174.51836 \r\nL 211.515778 174.980278 \r\nL 212.655717 160.243033 \r\nL 213.795656 162.175589 \r\nL 214.935594 158.029546 \r\nL 216.075533 166.048908 \r\nL 217.215472 169.274821 \r\nL 219.495349 177.45458 \r\nL 220.635288 182.428652 \r\nL 221.775227 177.529357 \r\nL 222.915165 173.715015 \r\nL 224.055104 166.308974 \r\nL 225.195043 162.663019 \r\nL 226.334981 167.206524 \r\nL 227.47492 167.105179 \r\nL 228.614859 169.812728 \r\nL 229.754798 167.681423 \r\nL 230.894736 166.770943 \r\nL 232.034675 174.104905 \r\nL 233.174614 183.400737 \r\nL 234.314552 174.820387 \r\nL 235.454491 162.440816 \r\nL 236.59443 178.660121 \r\nL 237.734369 172.324202 \r\nL 238.874307 179.508026 \r\nL 240.014246 174.764012 \r\nL 241.154185 176.629277 \r\nL 242.294123 176.323103 \r\nL 243.434062 172.782607 \r\nL 244.574001 168.494928 \r\nL 245.71394 169.321458 \r\nL 246.853878 176.745705 \r\nL 247.993817 183.013504 \r\nL 249.133756 164.480531 \r\nL 250.273694 166.462059 \r\nL 251.413633 172.094043 \r\nL 252.553572 176.108443 \r\nL 253.693511 184.766072 \r\nL 254.833449 177.018214 \r\nL 255.973388 173.588253 \r\nL 257.113327 181.87894 \r\nL 258.253265 183.263927 \r\nL 259.393204 183.013994 \r\nL 260.533143 178.266855 \r\nL 261.673082 177.963022 \r\nL 262.81302 178.411381 \r\nL 263.952959 177.343232 \r\nL 265.092898 182.658755 \r\nL 266.232836 171.555669 \r\nL 267.372775 177.063165 \r\nL 268.512714 173.082013 \r\nL 269.652653 171.099174 \r\nL 270.792591 174.107631 \r\nL 271.93253 180.99158 \r\nL 273.072469 172.694372 \r\nL 274.212407 176.664671 \r\nL 276.492285 189.884497 \r\nL 277.632224 187.392117 \r\nL 278.772162 175.544626 \r\nL 279.912101 178.139889 \r\nL 281.05204 182.005468 \r\nL 282.191978 180.535119 \r\nL 283.331917 187.689515 \r\nL 284.471856 189.492298 \r\nL 285.611795 182.899887 \r\nL 286.751733 182.985592 \r\nL 287.891672 184.507083 \r\nL 289.031611 172.215394 \r\nL 290.171549 173.163302 \r\nL 291.311488 169.994455 \r\nL 293.591366 181.191868 \r\nL 294.731304 181.725807 \r\nL 295.871243 186.628134 \r\nL 297.011182 190.460998 \r\nL 298.15112 186.519869 \r\nL 299.291059 183.551116 \r\nL 300.430998 177.090188 \r\nL 301.570937 172.201939 \r\nL 302.710875 176.063389 \r\nL 303.850814 175.105848 \r\nL 304.990753 178.389685 \r\nL 306.130691 178.782211 \r\nL 307.27063 175.627341 \r\nL 309.550508 191.500444 \r\nL 310.690446 184.968808 \r\nL 311.830385 172.909816 \r\nL 312.970324 186.230207 \r\nL 314.110262 180.364256 \r\nL 315.250201 187.601312 \r\nL 316.39014 183.559564 \r\nL 317.530079 185.085786 \r\nL 318.670017 183.435243 \r\nL 319.809956 181.445146 \r\nL 320.949895 177.986031 \r\nL 322.089833 179.262175 \r\nL 323.229772 183.696164 \r\nL 324.369711 189.70672 \r\nL 325.50965 173.641215 \r\nL 326.649588 175.775937 \r\nL 327.789527 180.258897 \r\nL 328.929466 183.874714 \r\nL 330.069404 191.413126 \r\nL 331.209343 184.228785 \r\nL 332.349282 181.643169 \r\nL 333.489221 187.177112 \r\nL 334.629159 189.418633 \r\nL 335.769098 189.482385 \r\nL 336.909037 186.073112 \r\nL 338.048975 184.091415 \r\nL 339.188914 185.705883 \r\nL 340.328853 183.962627 \r\nL 341.468791 189.079342 \r\nL 342.60873 178.173759 \r\nL 343.748669 183.160002 \r\nL 344.888608 179.583413 \r\nL 346.028546 179.588856 \r\nL 347.168485 181.264245 \r\nL 348.308424 185.953992 \r\nL 349.448362 179.631702 \r\nL 350.588301 183.163048 \r\nL 351.72824 189.624918 \r\nL 352.868179 194.02544 \r\nL 354.008117 194.174212 \r\nL 355.148056 183.619413 \r\nL 356.287995 184.659298 \r\nL 357.427933 188.710172 \r\nL 358.567872 186.585534 \r\nL 359.707811 192.164784 \r\nL 360.84775 194.928761 \r\nL 361.987688 188.942684 \r\nL 363.127627 187.728859 \r\nL 364.267566 189.40742 \r\nL 365.407504 180.110826 \r\nL 366.547443 179.818242 \r\nL 366.547443 179.818242 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 46.965625 228.439219 \r\nL 46.965625 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 381.765625 228.439219 \r\nL 381.765625 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 46.965625 228.439219 \r\nL 381.765625 228.439219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 46.965625 10.999219 \r\nL 381.765625 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pc436fa5fe4\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "퍼플렉서티 평가 중 ...\n234 / 235\n테스트 퍼플렉서티:  136.39106711546\n"
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100       # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35          # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용해서 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매게변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 나은 RnnLm 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)                             # 가중치 공유\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모으기\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'TimeSoftmaxWithLoss' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f5300d81c87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mbest_ppl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mppl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Shin\\Develop\\python\\Machine-Learning\\밑바닥부터 시작하는 딥러닝2\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-b5695329b6fc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs, ts, train_flg)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_flg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TimeSoftmaxWithLoss' object is not callable"
     ]
    }
   ],
   "source": [
    "from common import config\n",
    "config.GPU = True\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "    \n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "    trainer.plot(ylim=(0, 500))\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매게변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}